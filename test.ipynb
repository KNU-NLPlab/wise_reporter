{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules/multi_summ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Scouter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.1 s, sys: 1.15 s, total: 5.25 s\n",
      "Wall time: 4.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from modules.scouter_handler import ScouterHandler\n",
    "from modules.scouter.config import default_addr, default_newspaper_idx, default_timeline_idx\n",
    "from modules.topic_generator import TopicGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"삼성전자\"\n",
    "out_path = \"results/\"\n",
    "\n",
    "scouter = ScouterHandler(addr=default_addr, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query : 삼성전자\n",
      "Scroll idx : 1 (1000 docs)\n",
      "Scroll idx : 2 (1000 docs)\n",
      "Total retrieved Doc # :  2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_body = scouter.make_keyword_query_body(keyword, filters=['news_id', 'postingDate', 'newsTitle', 'extContent', 'analyzed_text'])\n",
    "doc_info_list = scouter.search(query_body, data_type=default_newspaper_idx, max_num_doc=2000, trim_lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'세계 최대 자산운용사인 블랙록이 삼성전자 지분 5.03%를 보유하고 있다고 공시했다. 블랙록은 지난 1월에만 삼성전자 지분 950억원어치를 매입하며 지분율을 확대했다. 7일 블랙록은 지난달 장내매수로 삼성전자 지분을 5%  이상 보유하게 됐다고 공시했다. 지난 1월에 삼성전자 주식 약 211만주를 순매수했고, 매수단가를 기준으로 한 취득 규모는 약 950억원이다. 지난달 블랙록은 삼성전자 주식을 한 주당 4만5000원대에서 집중 매입했다. 이날 삼성전자 주가는 전 거래일보다 150원(0.32%) 하락한 4만6200원으로 장을 마쳤다.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_info_list[0]['extContent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 keywords : ['수출', '부진', '경상흑자']\n",
      "Topic 1 news article & # of doc 9:\n",
      "불황형 흑자 의 그늘 경상수지 흑자 27분기 만에 최저\n",
      "불안한 경상흑자  1분기 6년9개월만에 최소...4월 적자 가능성(종합)\n",
      "수출 부진  쪼그라든 경상흑자 4월 적자 전환하나?\n",
      "수출 부진에 경상수지  휘청  6년9개월만 흑자 최소(종합)\n",
      "수출 부진  1분기 경상흑자 112.5억달러...6년9개월만에  최소\n",
      "1분기 경상수지 6년9개월 만에 최저 수출 부진 속  불황형 흑자\n",
      "1분기 경상수지 흑자 112.5억달러 2012년 이후 최소\n",
      "경상수지 83개월 흑자행진에도...규모는 7년 만에 최소\n",
      "경상수지 83개월 연속 흑자 끊기나 외국인 배당금이 좌우\n",
      "\n",
      "Topic 2 keywords : ['트럼프', '시진핑', '관세']\n",
      "Topic 2 news article & # of doc 15:\n",
      "트럼프  추가 관세  위협 속 미중 9∼10일 무역협상 나선다\n",
      "뉴욕증시, 미중 무역협상 우려 다시 커지며 급락 다우 1.79%\n",
      "무역전쟁 우려에 美증시   관세 위협, 위험으로 인식\n",
      "中언론  美과 무역협상 어려움 대처할 자신있다\n",
      "채권왕  건들락, 美 관세 인상 가능성 50%\n",
      "美 3250억弗 대중 추가관세 실행 불가능\n",
      "中 4월 수출 전년比 2.7%  대미 무역도 급감\n",
      "미 중 마지막 단두대 협상 류허의 입에 달렸다\n",
      "미중 무역전쟁 우려, 亞증시 줄줄이 하락\n",
      "트럼프 블러핑 김정은에겐 통했는데 시진핑은?\n",
      "엄포 아니었다 美  10일 중국산 관세 10% 25%로 인상\n",
      "中 트럼프 협박에도 협상 계속하는 진짜 이유는?\n",
      "美 中  무역전쟁  위기 뉴욕증시 급락, 코스피 꿈틀\n",
      "트럼프 관세  카운트다운  美월가  최악 대비하라  경고\n",
      "한번 해보자  중국도 강경파들 급속히 입지 넓혀\n",
      "\n",
      "Topic 3 keywords : ['EU', '유로존', '하락']\n",
      "Topic 3 news article & # of doc 8:\n",
      "EU, 유로존 GDP 성장률 하향 조정 1.3% 1.2%(종합)\n",
      "1Q  깜짝성장 에도 눈높이 낮춘 유럽, 이유가\n",
      "하루 늦은 충격  미-유럽증시 급락, 상품가격도 하락\n",
      "독 지멘스, 발전 사업 축소하며 4년간 1만명 감축 방침\n",
      "유럽 증시, 미중 무역협상 우려에 크게 하락 마감..런던 1.63%\n",
      "미중 무역전쟁 우려에 글로벌 시장 출렁 주가 구리\n",
      "미중 무역협상  노 딜  우려, 亞증시 일제 하락\n",
      "트럼프 관세  카운트다운  美월가  최악 대비하라  경고\n",
      "\n",
      "Topic 4 keywords : ['주택', '공사', 'MBS']\n",
      "Topic 4 news article & # of doc 9:\n",
      "개인도 주택금융공사 발행 MBS 투자 가능해진다\n",
      "오는 27일부터 단돈 1만원으로도 MBS 직접투자 가능해진다\n",
      "개인투자자도 주금공 발행 MBS 투자할 수 있다\n",
      "개인도 소액으로 주금공 발행 MBS 직접투자 가능해진다\n",
      "개인도 주택저당증권(MBS) 소액투자 가능해진다\n",
      "개인도 1만원 단위로 MBS 직접투자 가능해진다\n",
      "개인도 27일부터 주택금융공사 MBS 소액투자 가능해져\n",
      "주택저당증권(MBS) 개인 소액투자 문  활짝\n",
      "개인도 MBS 소액 투자 가능해진다\n",
      "\n",
      "Topic 5 keywords : ['브렉시트', '메이 총리', '英']\n",
      "Topic 5 news article & # of doc 10:\n",
      "글로벌 기업 CFO 35.6%  브렉시트 시한 또 연장될 것\n",
      "英 중앙은행, 브렉시트 연기에 기준금리 0.75% 동결\n",
      "뉴욕증시, 미중 무역협상 우려 다시 커지며 급락 다우 1.79%\n",
      "英, 기준금리 0.75% 동결 올해 성장률 전망 1.2% 1.5% 상향\n",
      "영국 기업 14% 재무상태  심각\n",
      "영국은행, 올 성장치 전망 1.6%로 상향\n",
      "유로존 올 성장률 전망 또 낮춘 EU\n",
      "美 연준, 무역전쟁에 고심    금융안정 위협할 최대 요인\n",
      "1Q  깜짝성장 에도 눈높이 낮춘 유럽, 이유가\n",
      "英자동차 생산 14% 하락 향후 전망  더욱 나쁨\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date = '2019-05-08'\n",
    "topic_gen = TopicGenerator(keyword, out_path)\n",
    "topic_doc = topic_gen.process_data(date)\n",
    "clusters = topic_doc['clusters']\n",
    "\n",
    "for i in range(len(clusters)):\n",
    "    print('Topic {} keywords :'.format(i+1), clusters[i]['keywords'])\n",
    "    print('Topic {} news article & # of doc {}:'.format(i+1, len(clusters[i]['news_source'])))\n",
    "    for doc in clusters[i]['news_source']:\n",
    "        print(doc['newsTitle'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query : 삼성전자\n"
     ]
    }
   ],
   "source": [
    "query_body = ScouterHandler.make_count_query_body(keyword, from_date=\"2019-05-01\", to_date=\"2019-12-31\")\n",
    "trend_data = scouter.search_for_trend(query_body, max_num_doc=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'2019-05-01': 21,\n",
       "         '2019-05-02': 77,\n",
       "         '2019-05-03': 33,\n",
       "         '2019-05-04': 4,\n",
       "         '2019-05-05': 5,\n",
       "         '2019-05-06': 16,\n",
       "         '2019-05-07': 37,\n",
       "         '2019-05-08': 50,\n",
       "         '2019-05-09': 43,\n",
       "         '2019-05-10': 25,\n",
       "         '2019-05-11': 3,\n",
       "         '2019-05-12': 11,\n",
       "         '2019-05-13': 35,\n",
       "         '2019-05-14': 27,\n",
       "         '2019-05-15': 44,\n",
       "         '2019-05-16': 48,\n",
       "         '2019-05-17': 41,\n",
       "         '2019-05-18': 3,\n",
       "         '2019-05-19': 8,\n",
       "         '2019-05-20': 49,\n",
       "         '2019-05-21': 72,\n",
       "         '2019-05-22': 46,\n",
       "         '2019-05-23': 51,\n",
       "         '2019-05-24': 29,\n",
       "         '2019-05-25': 5,\n",
       "         '2019-05-26': 15,\n",
       "         '2019-05-27': 36,\n",
       "         '2019-05-28': 59,\n",
       "         '2019-05-29': 37,\n",
       "         '2019-05-30': 50,\n",
       "         '2019-05-31': 27})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter({d['key_as_string']:d['doc_count'] for d in trend_data['aggregations']['date_range']['buckets'][0]['group_by_date']['buckets']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 2. Multi-document Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.38 s, sys: 1 s, total: 5.38 s\n",
      "Wall time: 5.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from modules.multi_doc_summary import MultiDocSummary\n",
    "\n",
    "multi_doc_summarizer = MultiDocSummary('0', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'유럽연합(eu)이 중국과의 무역협상 타결 가능성을 시사했다. 미중간 무역 긴장이 고조되면서 유로존의 올해 gdp 성장 전망치는 1.4%에서 1.4%로 낮아질 것으로 내다봤다. 미중 무역분쟁 긴장 고조로 유로존 경제에 부담이 가중될 수 있다는 경고다. '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_doc_summarizer.process_data([doc['extContent'] for doc in clusters[2]['news_source']][:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. TimelineSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from modules.timeline_summary import TimelineSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = '미국 중국 무역'\n",
    "outpath = './results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query : 미국 중국 무역\n",
      "Scroll idx : 1 (200 docs)\n",
      "Total retrieved Doc # :  200\n",
      "\n",
      "CPU times: user 148 ms, sys: 40 ms, total: 188 ms\n",
      "Wall time: 602 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scouter = ScouterHandler(addr=default_addr, size=1000)\n",
    "query_body = scouter.make_keyword_query_body(keyword, filters=['news_id', 'postingDate', 'extContent', 'extract'])\n",
    "doc_info_list = scouter.search(query_body, data_type=default_timeline_idx, max_num_doc=200, trim_lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A :  0.006771564483642578\n",
      "B :  0.13193631172180176\n",
      "C :  0.009744405746459961\n",
      "C-sub :  0.02000284194946289\n",
      " >> phase 4. calculate next nodes\n",
      "timeline\n",
      "['2017-09-20', '2018-11-15', '2018-11-29', '2019-01-08', '2019-05-07', '2019-05-11']\n",
      "date_idx: 1/6\n",
      "date_idx: 2/6\n",
      "date_idx: 3/6\n",
      "date_idx: 4/6\n",
      "date_idx: 5/6\n",
      " >> phase 4. Make beamsearch file\n",
      "D :  0.004508256912231445\n",
      "E :  0.2261819839477539\n",
      "CPU times: user 320 ms, sys: 80 ms, total: 400 ms\n",
      "Wall time: 395 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "timeline_summ = TimelineSummary(keyword, outpath)\n",
    "summary, _ = timeline_summ.process_data(doc_info_list)\n",
    "dates = [sentence['date'] for sentence in summary]\n",
    "timeline_sen = [' '.join(sentence['compResult']) for sentence in summary]\n",
    "normal_sentence = [sentence['article'][0]['sentence'].strip() for sentence in summary]\n",
    "score = [sentence['article'][2]['score'] for sentence in summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2017-09-20',\n",
       "  '신문은 아울러 트럼프 대통령의 다음달 방중을 앞두고 미국이 중국으로부터 많은 양보를 받아내려 하지만 중국은 굴복하지 않을 것이라고 덧붙였다.'),\n",
       " ('2018-11-15',\n",
       "  '장 초반부터 중국 정부가 미국에 무역변화 요구 관련 서면 답변서를 전달한 사실이 보도되면서 원/달러 환율을 끌어내렸다.'),\n",
       " ('2018-11-29', '프랑스 파리 증시의 CAC40 지수는 4,983.24로 장을 마쳐 전날 대비 변동이 없었다.'),\n",
       " ('2019-01-08', '미국과 중국의 무역분쟁으로 인해 지난해 글로벌 시장에서는 긴장이 고조됐다.'),\n",
       " ('2019-05-07',\n",
       "  '전날 중국 증시가 출렁이자 국영펀드와 중국공상은행 등이 나서 페트로차이나, 중국석유화공 등 대형주를 집중 사들이며 낙폭을 줄였다.'),\n",
       " ('2019-05-11',\n",
       "  '류 부총리가 이끄는 중국 대표단은 이날 워싱턴DC에서 로버트 라이트하이저 미국 무역대표부(USTR) 대표, 므누신 장관 등과 함께 무역회담을 가졌다.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(dates, normal_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2017-09-20',\n",
       "  '신문 은 트럼프 의 다음 달 을 고 이 많 은 양보 를 받 아 내 려 하 지만 중국 은 굴복 하 지 않 을 것 이 라고 었 다'),\n",
       " ('2018-11-15', '초반 정부 가 에 무역 요구 서 면 서 를 되 원  달러 환율 을 끌어내리 었 다'),\n",
       " ('2018-11-29', '프랑스 파리 증시 의 CAC 40 지수 는 4,983.24 로 장 을 마치 어 전날 대비 변동 이 없 다'),\n",
       " ('2019-01-08', '미국 과 무역 분쟁 으로 지난 글로벌 시장 에서 긴장 고조 되'),\n",
       " ('2019-05-07', '중국 증시 출렁이 국영 펀드 , 석유 를 집중 사들이 며 낙폭 을 줄이 었 다'),\n",
       " ('2019-05-11', '류 부 총리 가 중국 대표 단 은 라이트하이저 미국 무역 부 USTR , 과 함께 무역 회담 을 다 .')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(dates, timeline_sen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Image Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from modules.image_selector import ImageSelectionModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSelector = ImageSelectionModule(\"남북 정상회담\", \"aa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] DATE : 2019-05-08\n",
      "0 불황형 흑자 의 그늘 경상수지 흑자 27분기 만에 최저\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommended image : 1.jpg\n",
      "1 트럼프 추가 관세 위협 속 미중 9∼10일 무역협상 나선다\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommended image : 1.jpg\n",
      "2 EU, 유로존 GDP 성장률 하향 조정 1.3% 1.2%(종합)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected vgg16_input to have 4 dimensions, but got array with shape (0, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3f69621a212d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0msen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\s+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mimageSelector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./results/{}/{}-\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/workspace/wise_reporter/modules/image_selector.py\u001b[0m in \u001b[0;36mprocess_data\u001b[0;34m(self, query, image_save_path, download_limit)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mtopic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mfile_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaption_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_caption_downloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_limit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get candidate images and caption from google\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mnongraph_image_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnongraph_caption_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaption_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# filter images using vgg classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mfinal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msemantic_similarity_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnongraph_image_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnongraph_caption_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get final image through semantic similarity measurement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mimgsave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_save_path\u001b[0m \u001b[0;31m# path to save final recommended image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/wise_reporter/modules/image_selection/image_selection_2019_v1.py\u001b[0m in \u001b[0;36mVGG_classifier\u001b[0;34m(file_list, image_list, caption_list)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresized_image_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./modules/image_selection/weight_best.hdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;31m#    for i in range(len(test)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m#        print(file_list[i] + \" : , Predict : \"+ str(categories[predict[i]]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected vgg16_input to have 4 dimensions, but got array with shape (0, 1)"
     ]
    }
   ],
   "source": [
    "date_list = [\"2019-05-07\", \"2019-05-08\", \"2019-05-09\"]\n",
    "#for date in date_list:\n",
    "#    os.mkdir(\"./results/\"+date)\n",
    "\n",
    "result_list = [\n",
    "    [\n",
    "        \"트럼프의 뒤집기 전술에 딜레마 빠진 中 협상 해도 문제\",\n",
    "        \"韓외환보유액 순위 7개월만에 9위로 밀려 4월말 12억달러\",\n",
    "        \"엠플러스, 70억 2차전지 제조설비 공급.. 해외수주 증가\",\n",
    "        \"하나은행-주금공, 한부모가족 전세대출 요건완화 금리인하\",\n",
    "        \"관세전쟁 악몽 재현  코스피 2170선붕괴\"\n",
    "    ],\n",
    "    [\n",
    "        \"불황형 흑자 의 그늘 경상수지 흑자 27분기 만에 최저\",\n",
    "        \"트럼프 추가 관세 위협 속 미중 9∼10일 무역협상 나선다\",\n",
    "        \"EU, 유로존 GDP 성장률 하향 조정 1.3% 1.2%(종합)\",\n",
    "        \"개인도 주택금융공사 발행 MBS 투자 가능해진다\",\n",
    "        \"글로벌 기업 CFO 35.6%  브렉시트 시한 또 연장될 것\"\n",
    "    ],\n",
    "    [\n",
    "        \"끝나지 않은 무역전쟁 악몽\",\n",
    "        \"중고차 대출한도, 차값의 110% 이내로 제한된다\",\n",
    "        \"비씨카드 이제 중국에서 모바일로 결제하세요\",\n",
    "        \"한은, 새로운 금융상황지수 도입... 2017년 4분기 이후 완화기조 지속\",\n",
    "        \"삼성자산운용, 개인연금 설정액 1조 돌파\"\n",
    "    ]\n",
    "]\n",
    "for date, sen_list in zip(date_list[1:], result_list[1:]):\n",
    "    print(\"[*] DATE : \" + date)\n",
    "    for i, sen in enumerate(sen_list):\n",
    "        sen = re.sub(\"\\s+\", \" \", sen)\n",
    "        print(i, sen)\n",
    "        imageSelector.process_data(sen, \"./results/{}/{}-\".format(date, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.jpg : , Predict : others\n",
      "2.jpg : , Predict : others\n",
      "3.jpg : , Predict : others\n",
      "4.jpg : , Predict : others\n",
      "5.jpg : , Predict : others\n",
      "6.jpg : , Predict : others\n",
      "7.jpg : , Predict : others\n",
      "8.jpg : , Predict : others\n",
      "9.jpg : , Predict : others\n",
      "10.jpg : , Predict : others\n",
      "11.jpg : , Predict : others\n",
      "12.jpg : , Predict : others\n",
      "13.jpg : , Predict : others\n",
      "14.jpg : , Predict : graph\n",
      "15.jpg : , Predict : others\n",
      "16.jpg : , Predict : others\n",
      "17.jpg : , Predict : others\n",
      "18.jpg : , Predict : others\n",
      "19.jpg : , Predict : others\n",
      "20.jpg : , Predict : others\n",
      "21.jpg : , Predict : others\n",
      "22.jpg : , Predict : graph\n",
      "23.jpg : , Predict : others\n",
      "24.jpg : , Predict : others\n",
      "25.jpg : , Predict : others\n",
      "26.jpg : , Predict : others\n",
      "27.jpg : , Predict : others\n",
      "28.jpg : , Predict : graph\n",
      "29.jpg : , Predict : graph\n",
      "30.jpg : , Predict : others\n",
      "31.jpg : , Predict : others\n",
      "32.jpg : , Predict : graph\n",
      "33.jpg : , Predict : others\n",
      "34.jpg : , Predict : others\n",
      "35.jpg : , Predict : others\n",
      "36.jpg : , Predict : graph\n",
      "37.jpg : , Predict : others\n",
      "38.jpg : , Predict : graph\n",
      "39.jpg : , Predict : others\n",
      "40.jpg : , Predict : others\n",
      "41.jpg : , Predict : others\n",
      "42.jpg : , Predict : graph\n",
      "43.jpg : , Predict : others\n",
      "44.jpg : , Predict : others\n",
      "45.jpg : , Predict : others\n",
      "46.jpg : , Predict : graph\n",
      "47.jpg : , Predict : others\n",
      "48.jpg : , Predict : others\n",
      "49.jpg : , Predict : graph\n",
      "50.jpg : , Predict : others\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommended image : 1.jpg\n"
     ]
    }
   ],
   "source": [
    "imageSelector.process_data(\"테리사 메이 영국 총리는 표결 직후 성명을 통해 예고한 대로 13일 노딜 브렉시트 여부를 하원 표결에 부치겠다고 밝혔다.\", \"./abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] DATE : 2019-05-07\n",
      "0 지난해(181억7000만달러)에 비해 증가 폭이 줄었지만 한국 외환보유액은 10년간 증가세를 보이며 두 배로 확대됐다.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected vgg16_input to have 4 dimensions, but got array with shape (0, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0048be82f215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0msen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\s+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mimageSelector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./results/{}/timeline-{}-\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/workspace/wise_reporter/modules/image_selector.py\u001b[0m in \u001b[0;36mprocess_data\u001b[0;34m(self, query, image_save_path, download_limit)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mtopic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mfile_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaption_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_caption_downloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_limit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get candidate images and caption from google\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mnongraph_image_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnongraph_caption_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaption_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# filter images using vgg classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mfinal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msemantic_similarity_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnongraph_image_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnongraph_caption_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get final image through semantic similarity measurement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mimgsave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_save_path\u001b[0m \u001b[0;31m# path to save final recommended image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/wise_reporter/modules/image_selection/image_selection_2019_v1.py\u001b[0m in \u001b[0;36mVGG_classifier\u001b[0;34m(file_list, image_list, caption_list)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresized_image_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./modules/image_selection/weight_best.hdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;31m#    for i in range(len(test)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m#        print(file_list[i] + \" : , Predict : \"+ str(categories[predict[i]]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected vgg16_input to have 4 dimensions, but got array with shape (0, 1)"
     ]
    }
   ],
   "source": [
    "result_list = [\n",
    "    [\n",
    "        \"지난해(181억7000만달러)에 비해 증가 폭이 줄었지만 한국 외환보유액은 10년간 증가세를 보이며 두 배로 확대됐다.\",\n",
    "        \"지난달 외환보유액이 4,055억 달러로 사상 최대 기록을 다시 갈아치웠다.\",\n",
    "        \"외환보유액 1위 중국 3만879억달러, 2위는 일본 1만2793억달러 우리나라의 외환보유액 규모는 2월말 기준 소폭 감소하며 세계 8위 수준(1월)을 유지한 것으로 나타났다.\",\n",
    "        \"우리나라의 외환보유액은 지난해 8월말 4011억달러을 기록해 국가별 순위에서 인도(4001억달러)를 제치고 9위에서 8위로 올라선 바 있다.\"\n",
    "    ],\n",
    "    [\n",
    "        \"15일(현지시간) 영국 하원에서 브렉시트 합의안이 큰 표 차로 부결되며 불확실성이 커진 점이 원/달러 환율 상승 배경인 것으로 풀이된다.\",\n",
    "        \"테리사 메이 영국 총리는 표결 직후 성명을 통해 예고한 대로 13일 노딜 브렉시트 여부를 하원 표결에 부치겠다고 밝혔다.\",\n",
    "        \"21~22일 EU정상회담 메이 빈손회담 가능성 커져 유럽연합(EU)이 브렉시트(영국의 EU 탈퇴) 시기 연기해달라는 영국의 요청에 영국 의회가 합의문을 승인해야 한다고 밝혔다.\"\n",
    "    ],\n",
    "    [\n",
    "        \"도널드 트럼프 미국 대통령이 오는 3월 1일까지였던 중국과의 무역 협상 시한을 연장하기로 했다.\",\n",
    "        \"겅솽 대변인의 발표를 앞두고 중국 상무부도 류허 중국 부총리가 오는 9~10일 예정대로 미국에서 협상을 벌일 것이라고 성명을 내기도 했다.\",\n",
    "        \"지난해 8월 22~23일 워싱턴DC에서는 왕서우원 중국 상무부 부부장과 데이비드 멀패스 미국 재무부 차관이 이끈 양국 협상 대표단이 무역협상을 진행했다.\",\n",
    "        \"중국 정부는 미국의 관세 폭탄 에 대응해 6월 1일부터 600억 달러 규모의 미국산 제품에 대해 5∼25%의 보복 관세를 부과하기로 했다.\",\n",
    "        \"미국 정부는 23일(현지시간) 자국 통화를 절하하는 국가들에 상계관세를 부과하는 규정을 추진한다고 밝혔다.\",\n",
    "        \"미국 재무부는 28일(현지시간) 한국과 중국, 일본을 포함한 9개국을 환율 관찰대상국으로 지정, 발표했다.\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "for date, sen_list in zip(date_list, result_list):\n",
    "    print(\"[*] DATE : \" + date)\n",
    "    for i, sen in enumerate(sen_list):\n",
    "        sen = re.sub(\"\\s+\", \" \", sen)\n",
    "        print(i, sen)\n",
    "        imageSelector.process_data(sen, \"./results/{}/timeline-{}-\".format(date, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Outlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 삼성전자의 올 2분기 실적이 매출액 58조9000억원, 영업이익 14조500억원으로 전년 동기에 비해 각각 15.7%, 72.5% 증가할 것으로 전망, 특히 영업이익이 시장의 기대치 12조9000억원을 상회할 것이라고 내다봤다.',\n",
       " ' 이베스트투자증권 어규진 연구원은  2분기에 메모리 가격 상승 및 OLED 패널 판매 호조가 지속되며 반도체와 디스플레이의 부품 사업부 실적 호조세가 지속될 전망 이라며  휴대폰 부분은 갤럭시S8 판매 호조에 따른 평균 판매가 상승 효과로 전작 대비 늦은 출시에도 견조한 실적을 유지할 전망 이라고 말했다.',\n",
       " ' 흥국증권 이민희 연구원은  삼성전자 2분기 영업이익 전망을 12조1000억원에서 13조원으로 상향 조정한다 며  메모리 가격 전망치 상향 조정과  노트7  리퍼폰 판매량을 일부 반영했다 고 설명했다.',\n",
       " ' 현 추세대로라면 올해 연간 수익률은 10% 안팎도 가능할 것이란 전망이 나오고 있다.',\n",
       " ' 따라서 올해 국내주식에서만 이미 20조원 가까운 수익을 올린 것으로 추정된다.',\n",
       " ' 이밖에 KB금융 LG전자 삼성SDI 엔씨소프트 현대차 등 종목에서도 올 들어 각각 3000억원 이상씩 평가차익을 올린 것으로 파악된다.',\n",
       " ' 자산운용업계 관계자는  국내 주식이 많이 올랐지만 늘어난 이익에 비해서는 여전히 전세계적으로 저평가된 상태 라면서  하반기 본격 시행을 앞두고 있는 스튜어드십코드(기관투자가 의결권 행사지침) 도입을 계기로 기업 배당이 늘어나고 지배구조가 개선되면서 하반기에도 국민연금이 국내주식에서 상당한 수익을 얻을 것으로 예상한다 고 말했다.',\n",
       " '반도체  슈퍼 호황 이 이어지면서 장비 소재주도 적잖은 수혜를 볼 것으로 기대되고 있다.',\n",
       " ' 전문가들은 반도체주가 코스피지수 상승을 이끌었듯이 반도체 장비 소재주가 코스닥시장 상승을 주도할 것이라는 분석을 내놓았다.',\n",
       " ' 시장조사업체 IHS마킷에 따르면 올해 D램 생산량은 지난해보다 1.1% 늘어나는 데 그칠 전망이다.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modules.outlook import ForecastSentence\n",
    "\n",
    "keyword = '삼성전자'\n",
    "outpath = 'result/'\n",
    "today = '2017-06-11'\n",
    "forecast = ForecastSentence(keyword, outpath)\n",
    "\n",
    "sentences = forecast.process_data(doc_info_list, today)\n",
    "sentences[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
