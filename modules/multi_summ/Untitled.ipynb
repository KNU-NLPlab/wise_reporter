{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = torch.load('dataset_m2s2/m2s_result_e26_acc_48.70_ppl_14.23.pt', map_location=lambda storage, loc: storage.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = 0\n",
    "\n",
    "for v in list(temp['model'].values()) + list(temp['generator'].values()):\n",
    "    size = v.size()\n",
    "    num_param = 1\n",
    "    for s in size:\n",
    "        num_param *= s\n",
    "        \n",
    "    num_params += num_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42779005"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _tally_parameters(model):\n",
    "    enc = 0\n",
    "    dec = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'encoder' in name:\n",
    "            enc += param.nelement()\n",
    "        else:\n",
    "            dec += param.nelement()\n",
    "    return enc + dec, enc, dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20052005"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight', \n",
       "              -3.8305e-01 -1.9328e-01  7.5459e-02  ...  -3.7031e-01 -7.3250e-02 -1.2196e-01\n",
       "               8.5339e-03 -4.9366e-02 -7.8776e-02  ...   5.6900e-03  8.6829e-02  7.7082e-03\n",
       "              -1.1174e+00 -2.6372e-01 -5.8367e-03  ...  -3.7273e-01 -3.4580e-01 -4.6648e-02\n",
       "                              ...                   ⋱                   ...                \n",
       "              -1.3917e+00 -2.3350e-01 -1.4691e-02  ...  -1.0663e-01 -5.2694e-02 -1.7786e-01\n",
       "              -9.7050e-01  2.5289e-01  1.0758e-01  ...  -7.0243e-01 -3.5976e-01  2.0875e-01\n",
       "              -1.5628e+00 -2.6239e-01 -1.8383e-01  ...  -2.8822e-01 -1.1533e-02 -1.2294e-01\n",
       "              [torch.FloatTensor of size 50004x400]), ('linear.bias', \n",
       "               8.5888e+00\n",
       "              -5.4686e-02\n",
       "              -1.1266e+01\n",
       "                   ⋮     \n",
       "              -2.7267e+00\n",
       "              -1.6193e+00\n",
       "              -7.7134e-01\n",
       "              [torch.FloatTensor of size 50004]), ('linear_copy.weight', \n",
       "              \n",
       "              Columns 0 to 9 \n",
       "              -0.6714 -0.0783 -0.1149  0.0804 -0.0599  0.0210 -0.0086  0.0291 -0.0131 -0.0508\n",
       "              \n",
       "              Columns 10 to 19 \n",
       "               0.1242  0.0486 -0.1093  0.0381 -0.2233 -0.0202 -0.2316 -0.0201  0.0125  0.0126\n",
       "              \n",
       "              Columns 20 to 29 \n",
       "              -0.0996 -0.0121 -0.0352 -0.0025 -0.0216  0.0363 -0.0007 -0.0016  0.0251  0.0532\n",
       "              \n",
       "              Columns 30 to 39 \n",
       "              -0.0717 -0.0336  0.0128 -0.0150 -0.0239  0.0993 -0.1531  0.0194 -0.0055  0.1129\n",
       "              \n",
       "              Columns 40 to 49 \n",
       "              -0.0399  0.0134  0.0370  0.0085 -0.0788 -0.0006 -0.0052  0.0105  0.0030 -0.0084\n",
       "              \n",
       "              Columns 50 to 59 \n",
       "              -0.1227 -0.0599  0.1322  0.0009  0.0047  0.0781  0.0337  0.0462 -0.0799  0.0144\n",
       "              \n",
       "              Columns 60 to 69 \n",
       "              -0.0233 -0.0484  0.0457 -0.0202 -0.0308  0.0059  0.0159  0.0416  0.0430  0.1019\n",
       "              \n",
       "              Columns 70 to 79 \n",
       "              -0.0667 -0.0541 -0.0146  0.0457  0.1174 -0.0306 -0.0501 -0.0507  0.0232  0.0364\n",
       "              \n",
       "              Columns 80 to 89 \n",
       "               0.0483 -0.1361 -0.0055 -0.0075 -0.0716  0.0787  0.0433  0.0067  0.0444  0.0231\n",
       "              \n",
       "              Columns 90 to 99 \n",
       "               0.0643  0.0029 -0.0247  0.0473 -0.0124 -0.2755  0.0133  0.0219  0.0334  0.0384\n",
       "              \n",
       "              Columns 100 to 109 \n",
       "              -0.4401  0.0386  0.0823 -0.0605 -0.0795 -0.0320 -0.0378 -0.0247  0.0243  0.0445\n",
       "              \n",
       "              Columns 110 to 119 \n",
       "               0.0402  0.1129  0.0146  0.0107  0.0497 -0.1444  0.0466  0.0146 -0.0090 -0.0973\n",
       "              \n",
       "              Columns 120 to 129 \n",
       "               0.0171 -0.0074  0.0602 -0.0159 -0.0221  0.0437 -0.0176 -0.0299  0.0720  0.0158\n",
       "              \n",
       "              Columns 130 to 139 \n",
       "               0.1752  0.0421 -0.0669  0.0297  0.0086 -0.0385  0.0755  0.0476  0.0282 -0.0412\n",
       "              \n",
       "              Columns 140 to 149 \n",
       "              -0.0736  0.0186  0.0306 -0.0378 -0.0693  0.0071  0.0855  0.0321 -0.0842 -0.0470\n",
       "              \n",
       "              Columns 150 to 159 \n",
       "              -0.0488 -0.0202 -0.0130 -0.1084  0.0049 -0.0760  0.0139  0.0299  0.0723  0.0018\n",
       "              \n",
       "              Columns 160 to 169 \n",
       "               0.0546  0.0199  0.1477 -0.0638  0.0392  0.0299 -0.0442 -0.0348  0.0243 -0.1115\n",
       "              \n",
       "              Columns 170 to 179 \n",
       "               0.0306  0.0517 -0.0030 -0.0134 -0.0050  0.0137  0.0778 -0.0213  0.0009 -0.0056\n",
       "              \n",
       "              Columns 180 to 189 \n",
       "              -0.0822 -0.0682 -0.0307  0.0441  0.1225  0.0626  0.0090 -0.0102  0.0001 -0.0010\n",
       "              \n",
       "              Columns 190 to 199 \n",
       "               0.0587 -0.0340  0.0276  0.0435  0.0141 -0.0496  0.1825 -0.0451  0.0336  0.0081\n",
       "              \n",
       "              Columns 200 to 209 \n",
       "               0.0119 -0.0366  0.0038 -0.6299 -0.4339 -0.0839 -0.0077  0.1346 -0.0095 -0.0358\n",
       "              \n",
       "              Columns 210 to 219 \n",
       "               0.0383  0.0029 -0.0067 -0.0171 -0.0074 -0.0960 -0.0002  0.0596 -0.0408  0.0279\n",
       "              \n",
       "              Columns 220 to 229 \n",
       "              -0.0006  0.0366  0.0315  0.0238  0.0969 -0.0497 -0.0059 -0.0444  0.0647  0.0347\n",
       "              \n",
       "              Columns 230 to 239 \n",
       "               0.0277  0.0440 -0.0206  0.0092 -0.0704 -0.0473  0.0212 -0.0809  0.0049  0.0303\n",
       "              \n",
       "              Columns 240 to 249 \n",
       "              -0.1325 -0.0686 -0.0311 -0.1217  0.1012  0.1129  0.0139 -0.0283 -0.0627  0.0521\n",
       "              \n",
       "              Columns 250 to 259 \n",
       "               0.0621  0.0044  0.0199 -0.0147  0.0124  0.0798 -0.1546  0.0362  0.0061  0.0154\n",
       "              \n",
       "              Columns 260 to 269 \n",
       "               0.0807 -0.1617  0.0628  0.0140  0.0590 -0.0277  0.0292  0.0705 -0.0944  0.0797\n",
       "              \n",
       "              Columns 270 to 279 \n",
       "               0.0135 -0.0129 -0.0085 -0.0147  0.0674  0.0112 -0.0395 -0.0218  0.0017  0.0897\n",
       "              \n",
       "              Columns 280 to 289 \n",
       "              -0.0423 -0.0340  0.0102 -0.0331 -0.0200  0.0348  0.1397  0.0639  0.0543  0.0138\n",
       "              \n",
       "              Columns 290 to 299 \n",
       "               0.0529 -0.0201  0.0283 -0.0365 -0.1321  0.0791  0.0004 -0.0151  0.1103 -0.0259\n",
       "              \n",
       "              Columns 300 to 309 \n",
       "              -0.0457  0.0038  0.0474  0.0075 -0.0706 -0.0374  0.0234  0.0662 -0.0025 -0.0060\n",
       "              \n",
       "              Columns 310 to 319 \n",
       "               0.0444  0.0425  0.0110  0.0591 -0.0871  0.0361 -0.0228  0.0082 -0.0122 -0.0901\n",
       "              \n",
       "              Columns 320 to 329 \n",
       "              -0.0032  0.0549  0.0043  0.0080  0.0946 -0.0377 -0.0432  0.0963  0.0442  0.0365\n",
       "              \n",
       "              Columns 330 to 339 \n",
       "               0.0363 -0.1135 -0.1287 -0.0036 -0.0025  0.0263  0.0862 -0.0165  0.0968 -0.0562\n",
       "              \n",
       "              Columns 340 to 349 \n",
       "              -0.0154  0.0552 -0.0229 -0.0302  0.0013  0.1098  0.0546 -0.0369  0.0019  0.0135\n",
       "              \n",
       "              Columns 350 to 359 \n",
       "               0.1458  0.0439 -0.0192 -0.0331  0.0868 -0.0039  0.2169  0.0250  0.0235  0.0731\n",
       "              \n",
       "              Columns 360 to 369 \n",
       "              -0.2137 -0.0006 -0.0607 -0.0088  0.0711  0.0859  0.0140 -0.1017 -0.0401  0.0602\n",
       "              \n",
       "              Columns 370 to 379 \n",
       "              -0.1081 -0.0887 -0.1004  0.0137 -0.1279 -0.0746 -0.0209  0.0046 -0.0073 -0.0854\n",
       "              \n",
       "              Columns 380 to 389 \n",
       "               0.1108  0.0089 -0.0551 -0.0407  0.0857  0.0384 -0.0620 -0.0237  0.0422  0.2383\n",
       "              \n",
       "              Columns 390 to 399 \n",
       "              -0.0417  0.0370  0.0632 -0.1288  0.0959 -0.0703  0.0165  0.0962  0.0206 -0.1101\n",
       "              [torch.FloatTensor of size 1x400]), ('linear_copy.bias', \n",
       "              -1.0226\n",
       "              [torch.FloatTensor of size 1])])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['generator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
